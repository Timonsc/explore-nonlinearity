{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning Basic Principles 2018 - Data Analysis Project Report**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Exploring the possibilities of music genre classification using MLP* "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes: \n",
        "\n",
        "1) To run this code install keras, sklearn, pandas, numpy, tensorflow, imbalanced-learn and matplotlib\n",
        "- pip install -U imbalanced-learn\n",
        "- pip install keras\n",
        "- pip install tensorflow\n",
        "\n",
        "2) Run this code only from top to bottom. If you run the code in a different order you have to run it all again from top to bottom.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project I will explore the possibilities to make a MLP classifier that predicts the genre of songs. With different preprocessing techniques and parameters of the MLP I am going to find out if the MLP net can do better than logistic regression. By that we would find if there are nonlinear relations that can be used in the classification. The data used is several preprocessed statistics from several rythm, chroma and mfcc bands. Ultimately I concluded that the data did not contain significant non-linear relations and a model like binomial regression suffices for this particular dataset.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Rythm, chroma and mfcc statistics are a common technique to gather data about songs. These can be used to try and predict data about the songs.\n",
        "\n",
        "Problem statement: Can a MLP network find non-linear relations in rythm, chroma and mfcc band statistics to improve prediction of songs' genre?\n",
        "\n",
        "Motivation: If we can predict songs' genres, music services can suggest new songs that do not have any popularity data to users.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data analysis"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensionality of the data set is quite high. After setting up the first MLP the first task is to find if PCA feature selection can improve the first setup. Because if we can decrease the amount of features we can decrease the amount of nodes, and therefore train better with the small amount of objects. I tried many different ratios responsibility for the total variance and hoped to find results that were better than using all features. This was not the case, we had to keep all the features to get the best results.\n",
        "\n",
        "The training set was not randomly ordered, many objects from the first class came first in the data set. This does not work well with MLP as it will overfit to that class. We have to shuffle the data set.\n",
        "\n",
        "The dataset has features with different scales. A MLP will benefit heavily form standardizing the complete dataset. I tried normalizing as well but it had no effect.\n",
        "\n\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from IPython.display import HTML, display\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "from sklearn.decomposition import PCA\n",
        "from keras.models import Sequential, load_model\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import History\n",
        "from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "#...\n"
      ],
      "outputs": [],
      "execution_count": 99,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rawdata = pd.read_csv('..\\\\all\\\\train_data.csv', header=None)\n",
        "test = pd.read_csv( '..\\\\all\\\\test_data.csv', header=None)\n",
        "rawlabels = pd.read_csv('..\\\\all\\\\train_labels.csv', header=None)\n",
        "num_samples = rawdata.shape[0]\n",
        "train = int(0.8*num_samples)"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions that load the data, preprocess the data, and save results of the ML algorithms. \n",
        "\n",
        "def load_data():\n",
        "    \n",
        "    data,labels = shuffle_training_data(rawdata,rawlabels)\n",
        "\n",
        "    #datatrain, datatest, labelstest, labelstrain = split_into_train_and_test(data,labels)\n",
        "    labels = np.ravel(labels)\n",
        "    data = standardize(data)\n",
        "    data,labels = smote(data,labels)\n",
        "    \n",
        "    #print(data.shape)\n",
        "    #np.ravel(labels)\n",
        "    features,pca_data = get_pca_features_data(data,fractions[0]) # tried to find out if the neural network would perform better with pca features only\n",
        "    return data, labels\n",
        "\n",
        "def shuffle_training_data (data,labels):\n",
        "    data = np.matrix(data)\n",
        "    y = np.ravel(labels)\n",
        "    datalabel = np.zeros((data.shape[0], data.shape[1]+1))\n",
        "    datalabel[:, :-1] = data\n",
        "    datalabel[:, -1] = y\n",
        "    np.random.shuffle(datalabel)\n",
        "    data = datalabel[:, :-1]\n",
        "    #print(\"Data Shape:\",data.shape)\n",
        "    label = np.transpose(np.matrix(datalabel[:, -1]))\n",
        "    #print(\"Label Shape:\",label.shape)\n",
        "    return data,label\n",
        "\n",
        "def standardize(data):\n",
        "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True).fit(data)\n",
        "    return scaler.transform(data) #, scaler.transform(datatest)\n",
        "\n",
        "def normalize(datatrain, datatest):\n",
        "    scaler = Normalizer().fit(datatrain)\n",
        "    return scaler.transform(datatrain), scaler.transform(datatest)\n",
        "\n",
        "def split_into_train_and_test(data,labels):\n",
        "    labels = labels - 1\n",
        "    labels = keras.utils.to_categorical(labels, num_classes=10)\n",
        "    #print(labels.shape)\n",
        "    #print(\"labels\",labels)\n",
        "    labelstest = labels[train:num_samples]\n",
        "    labelstrain = labels[0:train]\n",
        "    datatest = data[train:num_samples]\n",
        "    datatrain = data[0:train]\n",
        "    #datatrain, datatest = normalize(datatrain, datatest)\n",
        "    return datatrain,datatest,labelstest,labelstrain\n",
        "\n",
        "def smote(X,y):\n",
        "    X_resampled, y_resampled = BorderlineSMOTE().fit_resample(X, y)\n",
        "    #print(sorted(Counter(y_resampled).items()))\n",
        "    #print(y_resampled.shape)\n",
        "    y_resampled = np.transpose(np.matrix(y_resampled))\n",
        "    return X_resampled,y_resampled\n",
        "\n",
        "def pca(data,fraction_of_variance):\n",
        "    try:\n",
        "        eigvalues = np.load('eigvalues.npy')\n",
        "        eigvectors = np.load('eigvectors.npy')\n",
        "        print(\"Matices loaded.\")\n",
        "    except:\n",
        "        centered_data = data - np.mean(data, axis=0)\n",
        "        cov_mat = np.cov(centered_data, rowvar=False)\n",
        "        eigvalues, eigvectors = np.linalg.eig(cov_mat)\n",
        "        np.save('eigvalues.npy', eigvalues)\n",
        "        np.save('eigvectors.npy', eigvectors)\n",
        " \n",
        "    eigvalues = eigvalues.real\n",
        "    #print(eigvalues)\n",
        "    eigsortedindices = eigvalues.argsort()[::-1]\n",
        "   \n",
        "    sum_added_eigvalues,fraction = 0,0\n",
        "\n",
        "    features = []\n",
        "    eigvalues = eigvalues.real.tolist()\n",
        "    eigvallist = enumerate(eigvalues)\n",
        "    \n",
        "    total_variability = sum(eigvalues)\n",
        "    #print(total_variability)\n",
        "    #sortedeigvallist = sortedeigvalues.tolist()\n",
        "    sorted_enum_eigvallist = sorted(eigvallist, key=lambda x:x[1])[::-1]\n",
        "    #print(sorted_enum_eigvallist)\n",
        "    for index,value in sorted_enum_eigvallist:\n",
        "        #print(value,total_variability)\n",
        "        if(fraction < fraction_of_variance):\n",
        "            features.append(index)\n",
        "            sum_added_eigvalues = sum_added_eigvalues + value\n",
        "            fraction = sum_added_eigvalues / total_variability\n",
        "        else:\n",
        "            #print(fraction)\n",
        "            break    \n",
        "    #print(\"The following features explain\",str(100*fraction) + \"% of the variance\",features)\n",
        "    return features, eigvalues\n",
        "\n",
        "def plot_error(eigvalues,max_d):\n",
        "    x=range(1,max_d+1)\n",
        "    errors=[sum(eigvalues[d:]) for d in x]\n",
        "    plt.plot(x,errors)\n",
        "    plt.xlabel('Number of principal components $d$')\n",
        "    plt.ylabel('Reconstruction error $\\mathcal{E}$')\n",
        "    plt.title('Number of principal components vs the reconstruction error')\n",
        "    plt.show()\n",
        "    \n",
        "def get_pca_features_data(data,fraction):\n",
        "    column_features,eigvalues = pca(data,fraction)\n",
        "    pca_features_data = np.zeros((data.shape[0],len(column_features)))\n",
        "    i = 0 \n",
        "    for feature in column_features:\n",
        "        pca_features_data[:,i] = data[:,feature]\n",
        "        i=i+1\n",
        "    #print(\"These are the features that explain\",str(100*fraction) + \"% of the variance according to the principal component analysis:\")\n",
        "    #print(\"Columns from original data:\",column_features)\n",
        "    #print(pca_features_data)\n",
        "    return column_features,pca_features_data\n",
        "\n",
        "def save_result_in_txtfile(score,input_nodes,hidden_nodes):\n",
        "    report = 'Score: '+str(score)+'. Input nodes: '+str(input_nodes)+'. Hidden Nodes: '+str(hidden_nodes)+'. Optimizer: sgd.'\n",
        "    fh = open(\"results_test_different_hidden_nodes.txt\",\"a\")\n",
        "    fh.write(report)\n",
        "    fh.write(\"\\n\")\n",
        "    fh.close()\n",
        "    \n"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fractions were a list of fractions of the variance for calculating the most inportant features responsible for the total variance. It did not help for the predictions so this functionality doesn't work anymore. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "fractions = [1] #0.981,0.982,0.983,0.984,0.985,0.986,0.987,0.988,0.989,0.99,0.991,0.992,0.993,0.994,0.995,0.996,0.997,0.998,0.999,"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = load_data()\n",
        "\n",
        "datatrain = standardize(data)\n",
        "\nfeatures,pca_data = get_pca_features_data(datatrain,fractions[0]) # tried to find out if the neural network would perform better with pca features only"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matices loaded.\n",
            "Matices loaded.\n"
          ]
        }
      ],
      "execution_count": 46,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis of the input data\n",
        "means = []\n",
        "\n",
        "for i in range(rawdata.shape[1]):\n",
        "    #print(i)\n",
        "    #print(rawdata[i].describe())\n",
        "    means.append(rawdata[i].mean())\n",
        "\n",
        "means_rythm = means[0:168]\n",
        "means_chroma = means[169:216]\n",
        "means_mfcc = means[216:]\n",
        "\n",
        "print(\"Means of all features:\")\n",
        "plt.figure()\n",
        "plt.hold = True\n",
        "boxes=[]  \n",
        "boxes.append(means)\n",
        "plt.boxplot(boxes,vert=1)\n",
        "plt.show()\n",
        "\n",
        "print(\"Boxplot of means of all rythm features:\")\n",
        "plt.figure()\n",
        "plt.hold = True\n",
        "boxes=[]  \n",
        "boxes.append(means_rythm)\n",
        "plt.boxplot(boxes,vert=1)\n",
        "plt.show()\n",
        "\n",
        "print(\"Boxplot of means of all chroma features:\")\n",
        "plt.figure()\n",
        "plt.hold = True\n",
        "boxes=[]  \n",
        "boxes.append(means_chroma)\n",
        "plt.boxplot(boxes,vert=1)\n",
        "plt.show()\n",
        "\n",
        "print(\"Boxplot of means of all mfcc features:\")\n",
        "plt.figure()\n",
        "plt.hold = True\n",
        "boxes=[]  \n",
        "boxes.append(means_mfcc)\n",
        "plt.boxplot(boxes,vert=1)\n",
        "plt.show()\n",
        "\n",
        "print(\"Boxplots of means of all features compared:\")\n",
        "plt.figure()\n",
        "plt.hold = True\n",
        "boxes=[]  \n",
        "boxes.append(means_rythm)\n",
        "boxes.append(means_chroma)\n",
        "boxes.append(means_mfcc)\n",
        "plt.boxplot(boxes,vert=1)\n",
        "plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Means of all features:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": [
              "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\n"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boxplot of means of all rythm features:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": [
              "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\n"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boxplot of means of all chroma features:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": [
              "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\n"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boxplot of means of all mfcc features:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": [
              "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\n"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boxplots of means of all features compared:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": [
              "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\n"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 47,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see the variables differ quite a lot. Standardization will help the MLP to perform better."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(means_mfcc[0])\n",
        "print(means_mfcc[1])\n",
        "print(means_mfcc[2])\n",
        "print(means_mfcc[3])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000000.0\n",
            "1000000.0\n",
            "1000000.0\n",
            "1000000.0\n"
          ]
        }
      ],
      "execution_count": 48,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the plots we can see that there is one or more features that do not make sense and should be removed. I print all the feature.describe() to find it (uncomment if you wanna see it). "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The features in the columns 216, 217, 218 and 219 seem to be useless. I will remove them. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the columns from the data set\n",
        "rawdata.__delitem__(216)\n",
        "rawdata.__delitem__(217)\n",
        "rawdata.__delitem__(218)\n",
        "rawdata.__delitem__(219)\n",
        "\n",
        "test.__delitem__(216)\n",
        "test.__delitem__(217)\n",
        "test.__delitem__(218)\n",
        "test.__delitem__(219)\n",
        "\n",
        "# remove the means from the \n",
        "#means_rythm.pop()\n",
        "means_mfcc = means_mfcc[4:]\n"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(means_mfcc[1])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.010254128997043319\n"
          ]
        }
      ],
      "execution_count": 50,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Boxplot of means of all mfcc features:\")\n",
        "plt.figure()\n",
        "plt.hold = True\n",
        "boxes=[]  \n",
        "boxes.append(means_mfcc)\n",
        "plt.boxplot(boxes,vert=1)\n",
        "plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boxplot of means of all mfcc features:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": [
              "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\n"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 97,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = np.ravel(rawlabels)\n",
        "plt.hist(label_list, bins=[1, 2, 3,4,5,6,7,8,9,10])\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": [
              "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\n"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 52,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out if the training set is unbalanced I plotted the labels. The labes are heavily unbalanced and MLP's will need some adaptation to the model or data to prevent overfitting to the biggest classes. Either changing the weight updats according to the size of the class or some change to the trainingset. I chose for oversampling with the BorderlineSMOTE as it gave the best results. BorderlineSMOTE generates new objects for the unrepresented classes in a way that they won't interfere with the other classes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Methods and experiments"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "*- Explain your whole approach (you can include a block diagram showing the steps in your process).* \n",
        "\n",
        "*- What methods/algorithms, why were the methods chosen. *\n",
        "\n",
        "*- What evaluation methodology (cross CV, etc.).*\n",
        "\n",
        "- My basic approach was to train many models with the use of loops. By using loops in loops I was able to try many different combinations with different parameters under which: # of hidden nodes, # hidden layers, different amount of best features selected by the pca algorithm, optimizers, amount of dropout nodes, learning rate.\n",
        "- The MLP without hidden layer functions exactly the same as a logistic regression model. My interest was in adding a hidden layer to see if the MLP network finds non linear relations.\n",
        "- A problem with MLP nets is that it is relatively prone to overfitting. To solve this problem i had to use the dropout methodology where ever forward propagation the model only will use a part of the nodes of the complete network. Forces the network to look for multiple ways to predict its class. \n",
        "- I trained with many different optimizers. Though stochastic gradiend descent performed the best. Especially with a decay dictated by the number of the epoch it is training in a good rate was ensured.\n",
        "- With a high momentum I was ensured to not find a local minimum."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi layer perceptron\n",
        "\n",
        "def create_model(lr, input_nodes, hidden_nodes):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Dropout(0.2, input_shape=(input_nodes,)))\n",
        "    model.add(Dense(hidden_nodes, activation='sigmoid'))    # *** You can remove these lines to see how the logistic regressino performs\n",
        "    model.add(layers.Dropout(0.5))                          # ***\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    sgd = keras.optimizers.SGD(lr=lr, decay=lr/epochs, momentum=0.8, nesterov=True)\n",
        "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_model(model, datatrain, labelstrain, datatest, labelstest, epochs, i):\n",
        "    #print(model.summary())\n",
        "    history = History()\n",
        "    history = model.fit(datatrain, labelstrain, epochs=epochs, validation_split=0.33,batch_size=28, callbacks=[history],verbose=0)\n",
        "    score = model.evaluate(datatest, labelstest)\n",
        "    scores.append([i,[score[0],score[1]]])\n",
        "    model.save('model_'+str(i)+'.h5')\n",
        "    #loss = history.history['loss']\n",
        "    save_result_in_txtfile(score,input_nodes,hidden_nodes)\n",
        "    #plot_hist(history)\n",
        "    print(\"This model has a loss of\",score[0],\"and a accuracy of\",score[1])\n",
        "    \n",
        "    return score,scores\n",
        "\n",
        "def plot_hist(hist):\n",
        "    # Get training and test loss histories\n",
        "    training_loss = hist.history['loss']\n",
        "    test_loss = hist.history['val_loss']\n",
        "\n",
        "    # Create count of the number of epochs\n",
        "    epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "    # Visualize loss history\n",
        "    plt.plot(epoch_count, training_loss, 'r--')\n",
        "    plt.plot(epoch_count, test_loss, 'b-')\n",
        "    plt.legend(['Training Loss', 'Test Loss'])\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show();"
      ],
      "outputs": [],
      "execution_count": 93,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The parameters below, except input_nodes, can be changed for training. The current setting performed very good.*\n",
        "*If you want to compare it to the logistic regression model you can remove the hidden layer lines in the model denoted by # ***"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP parameters\n",
        "lr=0.1\n",
        "epochs = 60\n",
        "input_nodes = rawdata.shape[1]\n",
        "print(input_nodes)\n",
        "hidden_nodes = 260\n",
        "scores = []\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260\n"
          ]
        }
      ],
      "execution_count": 94,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*I used K-fold validation to make make sure that the comparison of the models are fair. Sometimes the a model can perform better if it is trained with a training set that happens to work out well for the testing. With k-fold you can prevent that.*"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold_model_creation_and_training(k):\n",
        "    n_folds = k\n",
        "    data, labels = load_data()\n",
        "    skf = StratifiedKFold(n_folds,True)\n",
        "    i = 1\n",
        "    for train, test in skf.split(data, labels):\n",
        "        print(\"Running Fold \"+str(i)+\"/\"+str(n_folds))\n",
        "        datatrain, datatest = data[train], data[test]\n",
        "        labelstrain, labelstest = labels[train], labels[test]\n",
        "        labelstrain, labelstest = labelstrain - 1, labelstest - 1\n",
        "        labelstrain,labelstest = keras.utils.to_categorical(labelstrain, num_classes=10),keras.utils.to_categorical(labelstest, num_classes=10)\n",
        "        model = None # Clearing the NN.\n",
        "        scores = None\n",
        "        model = create_model(lr,input_nodes,hidden_nodes)\n",
        "        score, scores = train_and_evaluate_model(model, datatrain, labelstrain, datatest, labelstest, epochs, i)\n",
        "        i = i + 1\n",
        "    print(scores)"
      ],
      "outputs": [],
      "execution_count": 95,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 102,
          "data": {
            "text/plain": [
              "0.9149678604224059"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 102,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# execute training and testing\n",
        "k_fold_model_creation_and_training(5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matices loaded.\n",
            "Running Fold 1/5\n",
            "4360/4360 [==============================] - 0s 18us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "This model has a loss of 1.107732417605339 and a accuracy of 0.6405963302752293\n",
            "Running Fold 2/5\n",
            "4360/4360 [==============================] - 0s 18us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "This model has a loss of 1.0955942489685269 and a accuracy of 0.6302752293577981\n",
            "Running Fold 3/5\n",
            "4360/4360 [==============================] - 0s 18us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "This model has a loss of 1.0975481313302977 and a accuracy of 0.6410550458715596\n",
            "Running Fold 4/5\n",
            "4350/4350 [==============================] - 0s 22us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "This model has a loss of 1.1385156438542507 and a accuracy of 0.6377011494732451\n",
            "Running Fold 5/5\n",
            "4350/4350 [==============================] - 0s 28us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "This model has a loss of 1.1199646554048035 and a accuracy of 0.6418390805077279\n",
            "[[1, [1.107732417605339, 0.6405963302752293]], [2, [1.0955942489685269, 0.6302752293577981]], [3, [1.0975481313302977, 0.6410550458715596]], [4, [1.1385156438542507, 0.6377011494732451]], [5, [1.1199646554048035, 0.6418390805077279]]]\n"
          ]
        }
      ],
      "execution_count": 96,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !! only used to output the csv files for the kaggle challenges. !!\n",
        "\n",
        "np.set_printoptions(threshold=10)\n",
        "model = load_model('model_5.h5')\n",
        "#print(datatrain.shape,test.shape)\n",
        "testdata = standardize(test)\n",
        "output = model.predict(testdata, batch_size=None, verbose=1, steps=None)\n",
        "sgd = keras.optimizers.SGD(lr=lr, decay=lr/epochs, momentum=0.8, nesterov=True)\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "sampleid = np.arange(output.shape[0])\n",
        "sampleid=sampleid+1\n",
        "#print(sampleid)\n",
        "matrix = np.ones((output.shape[0],output.shape[1]+1))\n",
        "matrix[:,0]=sampleid\n",
        "matrix[:,1:]=output\n",
        "classes = np.argmax(output,axis=1)\n",
        "classes = classes+1\n",
        "np.savetxt(\"submission.csv\", matrix,'%5.4f', delimiter=',', header=\"Sample_id,Class_1,Class_2,Class_3,Class_4,Class_5,Class_6,Class_7,Class_8,Class_9,Class_10\")\n",
        "matrix2 = np.ones((output.shape[0],2))\n",
        "matrix2[:,0]=sampleid\n",
        "matrix2[:,1]=classes\n",
        "np.savetxt(\"submission-class.csv\", matrix2,'%5.0f', delimiter=',', header=\"Sample_id,Sample_label\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6544/6544 [==============================] - 0s 60us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
          ]
        }
      ],
      "execution_count": 98,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Results"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Summarize the results of the experiments without discussing their implications.*\n",
        "\n",
        "*- Include both performance measures (accuracy and LogLoss).*\n",
        "\n",
        "*- How does it perform on kaggle compared to the train data.*\n",
        "\n",
        "*- Include a confusion matrix.*\n",
        "\n- See analysis in discussion/conclusion"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix ...\n",
        "#model.summary()\n",
        "data,labels = load_data()\n",
        "output_train = model.predict(data, batch_size=None, verbose=1, steps=None)\n",
        "#print(output_train.shape)\n",
        "classes = np.argmax(output_train,axis=1)\n",
        "pred_labels = classes + 1\n",
        "cm = confusion_matrix(labels,pred_labels)\n",
        "cmpd = pd.DataFrame(cm,columns=[str(i+1) for i in range(10)], index=[str(i+1) for i in range(10)])\n",
        "print(\"Confusion matrix:\")\n",
        "display(HTML(cmpd.to_html()))\n",
        "print()\n",
        "print(\"K-fold models with loss and accuracy:\")\n",
        "resultsdf = pd.DataFrame(scores)\n",
        "resultsdf.columns=[\"Model\",\"Loss, Accuracy\"]\n",
        "display(HTML(resultsdf.to_html()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matices loaded.\n",
            "21780/21780 [==============================] - 0s 20us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Confusion matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1631</td>\n",
              "      <td>167</td>\n",
              "      <td>34</td>\n",
              "      <td>69</td>\n",
              "      <td>105</td>\n",
              "      <td>111</td>\n",
              "      <td>51</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>125</td>\n",
              "      <td>1920</td>\n",
              "      <td>43</td>\n",
              "      <td>37</td>\n",
              "      <td>21</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>21</td>\n",
              "      <td>2110</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>2113</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>103</td>\n",
              "      <td>22</td>\n",
              "      <td>12</td>\n",
              "      <td>46</td>\n",
              "      <td>1955</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>50</td>\n",
              "      <td>17</td>\n",
              "      <td>33</td>\n",
              "      <td>43</td>\n",
              "      <td>23</td>\n",
              "      <td>2009</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>57</td>\n",
              "      <td>34</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>47</td>\n",
              "      <td>23</td>\n",
              "      <td>1981</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>982</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>23</td>\n",
              "      <td>167</td>\n",
              "      <td>293</td>\n",
              "      <td>44</td>\n",
              "      <td>658</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>58</td>\n",
              "      <td>143</td>\n",
              "      <td>780</td>\n",
              "      <td>41</td>\n",
              "      <td>279</td>\n",
              "      <td>476</td>\n",
              "      <td>105</td>\n",
              "      <td>0</td>\n",
              "      <td>296</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>373</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1251</td>\n",
              "      <td>189</td>\n",
              "      <td>127</td>\n",
              "      <td>83</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "K-fold models with loss and accuracy:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Loss, Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[1.015345358247057, 0.6674311926605505]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[1.0115077757780706, 0.664908256880734]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[1.0442600248056815, 0.6662844036697247]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[0.9895972582937658, 0.6836781609315297]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[0.9942914174342977, 0.6719540229885057]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 92,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classes:\n",
        "\n",
        "1 'Pop_Rock'\n",
        "\n",
        "2 'Electronic'\n",
        "\n",
        "3 'Rap'\n",
        "\n",
        "4 'Jazz'\n",
        "\n",
        "5 'Latin'\n",
        "\n",
        "6 'RnB'\n",
        "\n",
        "7 'International'\n",
        "\n",
        "8 'Country'\n",
        "\n",
        "9 'Reggae'\n",
        "\n",
        "10 'Blues'\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Discussion/Conclusions"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Interpret and explain your results *\n",
        "\n",
        "*- Discuss the relevance of the performance measures (accuracy and LogLoss) for\n",
        "imbalanced multiclass datasets. *\n",
        "\n",
        "*- How the results relate to the literature. *\n",
        "\n",
        "*- Suggestions for future research/improvement. *\n",
        "\n",
        "*- Did the study answer your questions? *\n",
        "\n",
        "- Reggae and Blues are completely mispredicted whereas others get relatively good results. My MLP has big trouble recognizing classes 9 and 10 as an unique genre. \n",
        "- On kaggle it performs very well in both the logloss and the accuracy. It will always perform one or two percentage points lower but that is normal as it is impossible to not overfit for a tiny bit. Though, overall it performs very stable and i chose to have one model for both kaggle challenges so I am very happy with the results. \n",
        "- I think the oversampling resulted in having a lower accuracy in the smaller classes. On the other hand it made sure that the model is very stable. I think it's a rather good trade-off. Also, the oversampling resulted in being able to train on many more samples (21k samples) as it generates samples for the smaller classes until they are as big as the biggest class. This is the reason why my MLP predicted the bigger classes very well and the smaller classes worse.\n",
        "- The PCA feature selection that i built in was absolutely useless. My biggest waste of time and effort so far in 2018. I hoped it to be useful for the model to be accurate with a smaller amount of nodes but it was not true. In the end, letting the MLP change the weights within the network and negating some features by itself was much more efficient and gave better results. \n",
        "- I think there was barely any improvement of adding the hidden layer. The logistic regression would have worked as well as the MLP with hidden layer. This will partially be the case since we are working with statistics of the actual data. I'm pretty sure that if we had the real data the MLP will work so much better.\n",
        "\n",
        "**Answer of the problem statement**: The MLP was with the current amount of preprocessing and fixed features selection performing slightly better than the logistic regression model. Though I've seen logistic regression models perform better than my MLP. Therefore the MLP net can make up for some preprocessing that I maybe didn't apply as well as the others did. That is a in a certain way a positive thing of the MLP as it is right now. On the other hand, in my opinion the result were not obvious enough to conclude that the MLP was able to find non linear relations in the data. \n",
        "\n**Future research:** The MLP might be able to find nonlinear relations if we had the actual data instead of the statistics. This is something to be research in the future. Also having more data would be beneficial for the MLP net.  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. References"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "*List of all the references cited in the document*"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix\n",
        "*Any additional material needed to complete the report can be included here. For example, if you want to keep  additional source code, additional images or plots, mathematical derivations, etc. The content should be relevant to the report and should help explain or visualize something mentioned earlier. **You can remove the whole Appendix section if there is no need for it.** *"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}